{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Deep Learning Seminar 1</h1>\n",
    "\n",
    "Credit cs231n.stanford.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">What was at Lecture?</h2>\n",
    "\n",
    "- Image Classification \n",
    "\n",
    "<img src=\"img/img-clf.png\" width=\"600\">\n",
    "\n",
    "- Linear Models (Что делает линейная модель простым языком)\n",
    "\n",
    "<img src=\"img/lm.png\" width=\"600\">\n",
    "<img src=\"img/lm-int.png\" width=\"600\">\n",
    "\n",
    "- Fully Connected Neural Nets\n",
    "\n",
    "<img src=\"img/fc-net.png\" width=\"600\">\n",
    "\n",
    "- Convolution Neural Nets (Какая мотивация при переходе к сверткам?)\n",
    "\n",
    "<img src=\"img/conv.png\" width=\"600\">\n",
    "\n",
    "- Зачем нужен backprop? \n",
    "\n",
    "<img src=\"img/bp.png\" width=\"600\">\n",
    "\n",
    "The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "\n",
    "- Что нужно накрутить на SGD чтобы получить хорошие методы стах оптимизации?\n",
    "\n",
    "<img src=\"img/adam.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">BackProp and Optimizers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import check_grad\n",
    "from gradient_check import eval_numerical_gradient_array\n",
    "\n",
    "def rel_error(x, y):\n",
    "      return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grad Check</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/gc.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Softmax Loss Layer</h3>\n",
    "<img src=\"img/loss.png\" width=\"300\">\n",
    "<img src=\"img/log.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def softmax_loss(x, y):\n",
    "    \"\"\"\n",
    "    Computes the loss and gradient for softmax classification.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data, of shape (N, C) where x[i, j] is the score for the jth class\n",
    "    for the ith input.\n",
    "    - y: Vector of labels, of shape (N,) where y[i] is the label for x[i] and\n",
    "    0 <= y[i] < C\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss: Scalar giving the loss\n",
    "    - dx: Gradient of the loss with respect to x\n",
    "    \"\"\"\n",
    "    \n",
    "    ### my_code_start ###\n",
    "    \n",
    "    # Calculating softmax\n",
    "    probs = np.exp(x - x.max(axis=1)[:, np.newaxis])\n",
    "    probs = probs / np.sum(probs, axis=1, keepdims=True)\n",
    "    \n",
    "    # Calculating loss\n",
    "    N = probs.shape[0]\n",
    "    loss = -np.log(probs[np.arange(N), y]).mean()\n",
    "    \n",
    "    # Calculating dx\n",
    "    dx = probs.copy()\n",
    "    dx[np.arange(N), y] -= 1\n",
    "    dx /= N\n",
    "    \n",
    "    ### my_code_end ###\n",
    "\n",
    "    return loss, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 3, 10)\n",
    "dx = lambda x: softmax_loss(x.reshape((10, 3)), y)[1].reshape(-1)\n",
    "loss = lambda x: softmax_loss(x.reshape((10, 3)), y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is a scalar\n",
      "1.16472230211\n"
     ]
    }
   ],
   "source": [
    "print 'loss is a scalar\\n', loss(np.random.random((10, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient is a matrix with shape 10x3\n",
      "[ 0.01922909 -0.06075527  0.04152618  0.02990461 -0.06352654  0.03362193\n",
      "  0.02674373  0.02252787 -0.04927161 -0.07768034  0.03242232  0.04525802\n",
      "  0.03982185 -0.07657901  0.03675716 -0.07822441  0.03696641  0.04125799\n",
      " -0.05925133  0.02542548  0.03382585 -0.04919979  0.02597576  0.02322403\n",
      "  0.02644686 -0.07179143  0.04534457  0.03120108 -0.05993998  0.0287389 ]\n"
     ]
    }
   ],
   "source": [
    "print 'gradient is a matrix with shape 10x3\\n', dx(np.random.random((10, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference should be ~10e-8 3.32179303249e-08\n"
     ]
    }
   ],
   "source": [
    "print 'difference should be ~10e-8', check_grad(loss, dx, np.random.random((10, 3)).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dense Layer</h3>\n",
    "<img src=\"img/lin.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine_forward(x, w, b):\n",
    "    \"\"\"\n",
    "    Computes the forward pass for an affine (fully-connected) layer.\n",
    "\n",
    "    The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N\n",
    "    examples, where each example x[i] has shape (d_1, ..., d_k). We will\n",
    "    reshape each input into a vector of dimension D = d_1 * ... * d_k, and\n",
    "    then transform it to an output vector of dimension M.\n",
    "\n",
    "    Inputs:\n",
    "    - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)\n",
    "    - w: A numpy array of weights, of shape (D, M)\n",
    "    - b: A numpy array of biases, of shape (M,)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: output, of shape (N, M)\n",
    "    - cache: (x, w, b)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the affine forward pass. Store the result in out. You     #\n",
    "    # will need to reshape the input into rows.                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    x_reshaped = np.reshape(x, (x.shape[0], -1))\n",
    "    out = x_reshaped.dot(w) + b\n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    cache = (x, w, b)\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.76985004799e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print 'Testing affine_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    Computes the backward pass for an affine layer.\n",
    "\n",
    "    Inputs:\n",
    "    - dout: Upstream derivative, of shape (N, M)\n",
    "    - cache: Tuple of:\n",
    "    - x: Input data, of shape (N, d_1, ... d_k)\n",
    "    - w: Weights, of shape (D, M)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient with respect to x, of shape (N, d1, ..., d_k)\n",
    "    - dw: Gradient with respect to w, of shape (D, M)\n",
    "    - db: Gradient with respect to b, of shape (M,)\n",
    "    \"\"\"\n",
    "    x, w, b = cache\n",
    "    dx, dw, db = None, None, None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the affine backward pass.                                 #\n",
    "    #############################################################################\n",
    "\n",
    "    dx = dout.dot(w.T).reshape(*x.shape)  # open tuple to t1, t2\n",
    "    dw = x.reshape((x.shape[0], -1)).T.dot(dout)\n",
    "    db = np.sum(dout, axis=0)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  1.40931342726e-10\n",
      "dw error:  7.92878649995e-08\n",
      "db error:  1.91103659929e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print 'Testing affine_backward function:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ReLu Layer</h3>\n",
    "\n",
    "$$ReLu(x) = max(0, x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_forward(x):\n",
    "    \"\"\"\n",
    "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
    "\n",
    "    Input:\n",
    "    - x: Inputs, of any shape\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: Output, of the same shape as x\n",
    "    - cache: x\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the ReLU forward pass.                                    #\n",
    "    #############################################################################\n",
    "    \n",
    "    out = np.maximum(0, x)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    cache = x\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-8\n",
    "print 'Testing relu_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
    "\n",
    "    Input:\n",
    "    - dout: Upstream derivatives, of any shape\n",
    "    - cache: Input x, of same shape as dout\n",
    "\n",
    "    Returns:\n",
    "    - dx: Gradient with respect to x\n",
    "    \"\"\"\n",
    "    dx, x = None, cache\n",
    "    #############################################################################\n",
    "    # TODO: Implement the ReLU backward pass.                                   #\n",
    "    #############################################################################\n",
    "    \n",
    "    dx = dout * (x > 0).astype(np.float32)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.27561468082e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-12\n",
    "print 'Testing relu_backward function:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Two Layer Fully Connected Neural Net with SGD</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10aef4490>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAFdCAYAAABGoXXzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYEulUmkj/f910vQR+z1bKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109852750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(X[5].reshape((8, 8)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t tr_loss inf \t te_loss inf \t te_acc 0.107407407407\n",
      "epoch 1000: \t tr_loss 5.26 \t te_loss 5.21 \t te_acc 0.688888888889\n",
      "epoch 2000: \t tr_loss 1.45 \t te_loss 2.66 \t te_acc 0.827777777778\n",
      "epoch 3000: \t tr_loss 1.72 \t te_loss 2.33 \t te_acc 0.85\n",
      "epoch 4000: \t tr_loss 0.69 \t te_loss 1.29 \t te_acc 0.887037037037\n",
      "epoch 5000: \t tr_loss 0.51 \t te_loss 1.30 \t te_acc 0.909259259259\n",
      "epoch 6000: \t tr_loss 1.35 \t te_loss 1.17 \t te_acc 0.905555555556\n",
      "epoch 7000: \t tr_loss 1.67 \t te_loss 1.78 \t te_acc 0.861111111111\n",
      "epoch 8000: \t tr_loss 0.57 \t te_loss 1.11 \t te_acc 0.925925925926\n",
      "epoch 9000: \t tr_loss 0.14 \t te_loss 0.92 \t te_acc 0.933333333333\n",
      "epoch 10000: \t tr_loss 0.18 \t te_loss 0.97 \t te_acc 0.912962962963\n",
      "epoch 11000: \t tr_loss 0.20 \t te_loss 0.83 \t te_acc 0.948148148148\n",
      "epoch 12000: \t tr_loss 0.22 \t te_loss 0.88 \t te_acc 0.937037037037\n",
      "epoch 13000: \t tr_loss 0.24 \t te_loss 0.85 \t te_acc 0.935185185185\n",
      "epoch 14000: \t tr_loss 0.34 \t te_loss 0.86 \t te_acc 0.935185185185\n",
      "epoch 15000: \t tr_loss 0.25 \t te_loss 0.89 \t te_acc 0.931481481481\n",
      "epoch 16000: \t tr_loss 0.26 \t te_loss 0.83 \t te_acc 0.940740740741\n",
      "epoch 17000: \t tr_loss 0.01 \t te_loss 0.83 \t te_acc 0.944444444444\n",
      "epoch 18000: \t tr_loss 0.40 \t te_loss 0.82 \t te_acc 0.942592592593\n",
      "epoch 19000: \t tr_loss 0.08 \t te_loss 0.79 \t te_acc 0.946296296296\n",
      "epoch 20000: \t tr_loss 0.36 \t te_loss 0.93 \t te_acc 0.914814814815\n",
      "epoch 21000: \t tr_loss 0.03 \t te_loss 0.76 \t te_acc 0.95\n",
      "epoch 22000: \t tr_loss 0.04 \t te_loss 0.79 \t te_acc 0.944444444444\n",
      "epoch 23000: \t tr_loss 0.17 \t te_loss 0.78 \t te_acc 0.948148148148\n",
      "epoch 24000: \t tr_loss 0.41 \t te_loss 0.80 \t te_acc 0.944444444444\n",
      "epoch 25000: \t tr_loss 0.15 \t te_loss 0.79 \t te_acc 0.944444444444\n",
      "epoch 26000: \t tr_loss 0.00 \t te_loss 0.78 \t te_acc 0.942592592593\n",
      "epoch 27000: \t tr_loss 0.07 \t te_loss 0.78 \t te_acc 0.944444444444\n",
      "epoch 28000: \t tr_loss 0.01 \t te_loss 0.81 \t te_acc 0.940740740741\n",
      "epoch 29000: \t tr_loss 0.06 \t te_loss 0.79 \t te_acc 0.948148148148\n",
      "epoch 30000: \t tr_loss 0.02 \t te_loss 0.77 \t te_acc 0.940740740741\n",
      "epoch 31000: \t tr_loss 0.10 \t te_loss 0.74 \t te_acc 0.946296296296\n",
      "epoch 32000: \t tr_loss 0.01 \t te_loss 0.74 \t te_acc 0.95\n",
      "epoch 33000: \t tr_loss 0.17 \t te_loss 0.75 \t te_acc 0.95\n",
      "epoch 34000: \t tr_loss 0.08 \t te_loss 0.77 \t te_acc 0.95\n",
      "epoch 35000: \t tr_loss 0.01 \t te_loss 0.74 \t te_acc 0.951851851852\n",
      "epoch 36000: \t tr_loss 0.00 \t te_loss 0.79 \t te_acc 0.944444444444\n",
      "epoch 37000: \t tr_loss 0.10 \t te_loss 0.75 \t te_acc 0.942592592593\n",
      "epoch 38000: \t tr_loss 0.01 \t te_loss 0.73 \t te_acc 0.95\n",
      "epoch 39000: \t tr_loss 0.00 \t te_loss 0.75 \t te_acc 0.946296296296\n",
      "epoch 40000: \t tr_loss 0.06 \t te_loss 0.75 \t te_acc 0.948148148148\n",
      "epoch 41000: \t tr_loss 0.04 \t te_loss 0.77 \t te_acc 0.942592592593\n",
      "epoch 42000: \t tr_loss 0.01 \t te_loss 0.73 \t te_acc 0.946296296296\n",
      "epoch 43000: \t tr_loss 0.01 \t te_loss 0.74 \t te_acc 0.946296296296\n",
      "epoch 44000: \t tr_loss 0.00 \t te_loss 0.77 \t te_acc 0.940740740741\n",
      "epoch 45000: \t tr_loss 0.03 \t te_loss 0.72 \t te_acc 0.948148148148\n",
      "epoch 46000: \t tr_loss 0.03 \t te_loss 0.73 \t te_acc 0.946296296296\n",
      "epoch 47000: \t tr_loss 0.05 \t te_loss 0.72 \t te_acc 0.95\n",
      "epoch 48000: \t tr_loss 0.02 \t te_loss 0.74 \t te_acc 0.946296296296\n",
      "epoch 49000: \t tr_loss 0.03 \t te_loss 0.72 \t te_acc 0.95\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = np.random.random((64, 100)), np.random.random(100)\n",
    "W2, b2 = np.random.random((100, 10)), np.random.random(10)\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "for i in range(50000):\n",
    "    batch_index = np.random.randint(0, X_train.shape[0], 100)\n",
    "    batch_X, batch_y = X_train[batch_index], y_train[batch_index]\n",
    "    \n",
    "    # ------------ Train ----------------- \n",
    "    # Forward Pass\n",
    "    out1, cache1 = affine_forward(batch_X, W1, b1) # Dense Layer\n",
    "    out2, cache2 = relu_forward(out1)              # ReLu Layer\n",
    "    out3, cache3 = affine_forward(out2,    W2, b2) # Dense Layer \n",
    "    tr_loss, dx = softmax_loss(out3, batch_y)      # Loss Layer \n",
    "    \n",
    "    # Backward Pass\n",
    "    dx, dW2, db2 = affine_backward(dx, cache3)\n",
    "    dx = relu_backward(dx, cache2)\n",
    "    dx, dW1, db1 = affine_backward(dx, cache1)\n",
    "    \n",
    "    # Updates\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    \n",
    "    # ------------ Test ----------------- \n",
    "    # Forward Pass\n",
    "    out1, cache1 = affine_forward(X_test, W1, b1) # Dense Layer\n",
    "    out2, cache2 = relu_forward(out1)              # ReLu Layer\n",
    "    out3, cache3 = affine_forward(out2,    W2, b2) # Dense Layer \n",
    "    te_loss, dx = softmax_loss(out3, y_test)         # Loss Layer \n",
    "    \n",
    "    # Predict\n",
    "    probs = np.exp(out3 - np.max(out3, axis=1, keepdims=True))\n",
    "    probs /= np.sum(probs, axis=1, keepdims=True)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print 'epoch %s:' % i, \n",
    "        print '\\t tr_loss %.2f' % tr_loss,\n",
    "        print '\\t te_loss %.2f' % te_loss,\n",
    "        print '\\t te_acc %s' % accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">What is the challenge? </h2>\n",
    "\n",
    "You will see in Assignment 1:\n",
    "- more layers and architectures (Dropout, Convolution, Pooling)\n",
    "- optimization (Momentum, Adam)\n",
    "- weight initialization \n",
    "- data augmentation \n",
    "- ...\n",
    "\n",
    "<img src=\"img/rw.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
