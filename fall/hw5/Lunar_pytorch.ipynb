{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "* Anton Karazeev, you can text me: [```anton.karazeev@gmail.com```](mailto:anton.karazeev@phystech.edu) or [t.me/akarazeev](https://t.me/akarazeev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reinforcement Learning (DQN) tutorial\n",
    "=====================================\n",
    "**Author**: `Adam Paszke <https://github.com/apaszke>`\n",
    "\n",
    "\n",
    "\n",
    "**Task**\n",
    "\n",
    "As the agent observes the current state of the environment and chooses\n",
    "an action, the environment *transitions* to a new state, and also\n",
    "returns a reward that indicates the consequences of the action. In this\n",
    "task, the environment terminates if the pole falls over too far.\n",
    "\n",
    "**Packages**\n",
    "\n",
    "\n",
    "First, let's import needed packages. Firstly, we need\n",
    "`gym <https://gym.openai.com/docs>` for the environment\n",
    "(Install using `pip install gym`).\n",
    "We'll also use the following from PyTorch:\n",
    "\n",
    "-  neural networks (``torch.nn``)\n",
    "-  optimization (``torch.optim``)\n",
    "-  automatic differentiation (``torch.autograd``)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 12:51:27,069] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Memory\n",
    "=======\n",
    "\n",
    "We'll be using experience replay memory for training our DQN. It stores\n",
    "the transitions that the agent observes, allowing us to reuse this data\n",
    "later. By sampling from it randomly, the transitions that build up a\n",
    "batch are decorrelated. It has been shown that this greatly stabilizes\n",
    "and improves the DQN training procedure.\n",
    "\n",
    "For this, we're going to need two classses:\n",
    "\n",
    "-  ``Transition`` - a named tuple representing a single transition in\n",
    "   our environment\n",
    "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
    "   transitions observed recently. It also implements a ``.sample()``\n",
    "   method for selecting a random batch of transitions for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our model. But first, let quickly recap what a DQN is.\n",
    "\n",
    "DQN algorithm\n",
    "=======\n",
    "\n",
    "Our environment is deterministic, so all equations presented here are\n",
    "also formulated deterministically for the sake of simplicity. In the\n",
    "reinforcement learning literature, they would also contain expectations\n",
    "over stochastic transitions in the environment.\n",
    "\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
    "$R_{t_0}$ is also known as the *return*. The discount,\n",
    "$\\gamma$, should be a constant between $0$ and $1$\n",
    "that ensures the sum converges. It makes rewards from the uncertain far\n",
    "future less important for our agent than the ones in the near future\n",
    "that it can be fairly confident about.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
    "us what our return would be, if we were to take an action in a given\n",
    "state, then we could easily construct a policy that maximizes our\n",
    "rewards:\n",
    "\n",
    "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
    "\n",
    "However, we don't know everything about the world, so we don't have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble\n",
    "$Q^*$.\n",
    "\n",
    "For our training update rule, we'll use a fact that every $Q$\n",
    "function for some policy obeys the Bellman equation:\n",
    "\n",
    "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
    "\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}\n",
    "\n",
    "To minimise this error, we will use the MSE loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "====\n",
    "\n",
    "Hyperparameters and utilities\n",
    "---------------------------\n",
    "This cell instantiates our model and its optimizer, and defines some\n",
    "utilities:\n",
    "\n",
    "-  ``Variable`` - this is a simple wrapper around\n",
    "   ``torch.autograd.Variable`` that will automatically send the data to\n",
    "   the GPU every time we construct a Variable.\n",
    "-  ``select_action`` - will select an action accordingly to an epsilon\n",
    "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
    "   the action, and sometimes we'll just sample one uniformly. The\n",
    "   probability of choosing a random action will start at ``EPS_START``\n",
    "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
    "   controls the rate of the decay.\n",
    "-  ``plot_durations`` - a helper for plotting the durations of episodes,\n",
    "   along with an average over the last 100 episodes (the measure used in\n",
    "   the official evaluations). The plot will be underneath the cell\n",
    "   containing the main training loop, and will update after every\n",
    "   episode.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.fc2 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.005\n",
    "EPS_DECAY = 100\n",
    "\n",
    "model = DQN()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state, model, exploration=True):\n",
    "    global steps_done\n",
    "    \n",
    "    if exploration is False:\n",
    "        # Testing case\n",
    "        return model(\n",
    "                Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        # Training case\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * steps_done / EPS_DECAY)\n",
    "        steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            return model(\n",
    "                Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            return LongTensor([[random.randrange(4)]])\n",
    "\n",
    "\n",
    "episode_rewards = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_rewards)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        \n",
    "\n",
    "def preprocess_state(state):\n",
    "    return torch.Tensor(state).unsqueeze(0).type(Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop\n",
    "=======\n",
    "\n",
    "Finally, the code for training our model.\n",
    "\n",
    "Here, you can find an ``optimize_model`` function that performs a\n",
    "single step of the optimization. It first samples a batch, concatenates\n",
    "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
    "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
    "loss. By defition we set $V(s) = 0$ if $s$ is a terminal\n",
    "state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_sync = 0\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "\n",
    "    # We don't want to backprop through the expected action values and volatile\n",
    "    # will save us on temporarily changing the model parameters'\n",
    "    # requires_grad to False!\n",
    "    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None]),\n",
    "                                     volatile=True)\n",
    "    state_batch = Variable(torch.cat(batch.state))\n",
    "    action_batch = Variable(torch.cat(batch.action))\n",
    "    reward_batch = Variable(torch.cat(batch.reward))\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = model(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(Tensor))\n",
    "    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0]\n",
    "    # Now, we don't want to mess up the loss with a volatile flag, so let's\n",
    "    # clear it. After this, we'll just end up with a Variable that has\n",
    "    # requires_grad=False\n",
    "    next_state_values.volatile = False\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute MSE loss\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the main training loop. At the beginning we reset\n",
    "the environment and initialize the ``state`` variable. Then, we sample\n",
    "an action, execute it, observe the next state and the reward (always\n",
    "1), and optimize our model once. When the episode ends (our model\n",
    "fails), we restart the loop.\n",
    "\n",
    "Below, `num_episodes` is set small. You should download\n",
    "the notebook and run lot more epsiodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112da04a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1413-7f0ca8d93c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mepisode_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1412-482b5e5c9f0d>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# detailed explanation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1401-8a02fe2167e6>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m         \u001b[0;31m# invariant:  non-selected at [0,n-i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# move non-selected item into vacancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/random.py\u001b[0m in \u001b[0;36m_randbelow\u001b[0;34m(self, n, int, maxsize, type, Method, BuiltinMethod)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n\u001b[0m\u001b[1;32m    223\u001b[0m                    Method=_MethodType, BuiltinMethod=_BuiltinMethodType):\n\u001b[1;32m    224\u001b[0m         \u001b[0;34m\"Return a random int in the range [0,n).  Raises ValueError if n==0.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112da04a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    state = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "\n",
    "    total_reward = 0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state, model)\n",
    "        next_state, reward, done, _ = env.step(action[0, 0])\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        next_state = preprocess_state(next_state)\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "#         env.render()\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        if done:\n",
    "            next_state = None\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_rewards.append(total_reward)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "env.render(close=True)\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-07 19:21:13,402] Making new env: LunarLander-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tLast length:   113\tAverage reward: -285.31\n",
      "Episode 20\tLast length:    93\tAverage reward: -343.31\n",
      "Episode 30\tLast length:   176\tAverage reward: -667.78\n",
      "Episode 40\tLast length:    69\tAverage reward: -634.14\n",
      "Episode 50\tLast length:   114\tAverage reward: -674.28\n",
      "Episode 60\tLast length:    69\tAverage reward: -643.25\n",
      "Episode 70\tLast length:   150\tAverage reward: -623.36\n",
      "Episode 80\tLast length:   154\tAverage reward: -568.43\n",
      "Episode 90\tLast length:   217\tAverage reward: -303.04\n",
      "Episode 100\tLast length:   149\tAverage reward: -129.72\n",
      "Episode 110\tLast length:   133\tAverage reward: -169.73\n",
      "Episode 120\tLast length:   262\tAverage reward: -219.53\n",
      "Episode 130\tLast length:   126\tAverage reward: -90.23\n",
      "Episode 140\tLast length:   116\tAverage reward: -129.66\n",
      "Episode 150\tLast length:   143\tAverage reward: -94.51\n",
      "Episode 160\tLast length:   136\tAverage reward: -154.80\n",
      "Episode 170\tLast length:   129\tAverage reward: -120.28\n",
      "Episode 180\tLast length:   237\tAverage reward: -77.72\n",
      "Episode 190\tLast length:   186\tAverage reward: -152.13\n",
      "Episode 200\tLast length:   135\tAverage reward: -109.63\n",
      "Episode 210\tLast length:   999\tAverage reward: -88.53\n",
      "Episode 220\tLast length:   163\tAverage reward: -54.28\n",
      "Episode 230\tLast length:   235\tAverage reward: -109.29\n",
      "Episode 240\tLast length:   999\tAverage reward: -32.05\n",
      "Episode 250\tLast length:   255\tAverage reward: -57.26\n",
      "Episode 260\tLast length:   181\tAverage reward: -102.58\n",
      "Episode 270\tLast length:   216\tAverage reward: -73.91\n",
      "Episode 280\tLast length:   213\tAverage reward: -146.28\n",
      "Episode 290\tLast length:   220\tAverage reward: -55.18\n",
      "Episode 300\tLast length:   397\tAverage reward: 20.11\n",
      "Episode 310\tLast length:   144\tAverage reward: -45.49\n",
      "Episode 320\tLast length:   226\tAverage reward: 15.99\n",
      "Episode 330\tLast length:   105\tAverage reward: -82.73\n",
      "Episode 340\tLast length:   208\tAverage reward: -36.51\n",
      "Episode 350\tLast length:   259\tAverage reward: -25.81\n",
      "Episode 360\tLast length:   737\tAverage reward: 19.03\n",
      "Episode 370\tLast length:   367\tAverage reward: 70.12\n",
      "Episode 380\tLast length:   163\tAverage reward: 41.75\n",
      "Episode 390\tLast length:   212\tAverage reward: -0.53\n",
      "Episode 400\tLast length:   303\tAverage reward: 114.52\n",
      "Episode 410\tLast length:   999\tAverage reward: 41.71\n",
      "Episode 420\tLast length:   999\tAverage reward: 37.66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-330b0d96b5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Don't infinite loop while learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-330b0d96b5cd>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "gamma = 0.99\n",
    "seed = 543\n",
    "log_interval = 10\n",
    "\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['action', 'value'])\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(8, 128)\n",
    "        self.action_head = nn.Linear(128, 4)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        return F.softmax(action_scores), state_values\n",
    "\n",
    "\n",
    "model = Policy()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=3e-2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    probs, state_value = model(Variable(state))\n",
    "    action = probs.multinomial()\n",
    "    model.saved_actions.append(SavedAction(action, state_value))\n",
    "    return action.data\n",
    "\n",
    "\n",
    "def finish_episode():\n",
    "    R = 0\n",
    "    saved_actions = model.saved_actions\n",
    "    value_loss = 0\n",
    "    rewards = []\n",
    "    for r in model.rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    for (action, value), r in zip(saved_actions, rewards):\n",
    "        reward = r - value.data[0,0]\n",
    "        action.reinforce(reward)\n",
    "        value_loss += F.smooth_l1_loss(value, Variable(torch.Tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    final_nodes = [value_loss] + list(map(lambda p: p.action, saved_actions))\n",
    "    gradients = [torch.ones(1)] + [None] * len(saved_actions)\n",
    "    autograd.backward(final_nodes, gradients)\n",
    "    optimizer.step()\n",
    "    del model.rewards[:]\n",
    "    del model.saved_actions[:]\n",
    "\n",
    "\n",
    "running_reward = 10\n",
    "total_reward = 0\n",
    "for i_episode in count(1):\n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(10000): # Don't infinite loop while learning\n",
    "        action = select_action(state)\n",
    "        state, reward, done, _ = env.step(action[0,0])\n",
    "        total_reward += reward\n",
    "        # if i_episode > 300:\n",
    "        #     env.render()\n",
    "        model.rewards.append(reward)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    running_reward = running_reward * 0.99 + t * 0.01\n",
    "    finish_episode()\n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}\\tLast length: {:5d}\\tAverage reward: {:.2f}'.format(\n",
    "            i_episode, t, total_reward / log_interval))\n",
    "        total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-07 19:26:50,947] Making new env: LunarLander-v2\n",
      "[2017-11-07 19:26:50,957] Making new env: LunarLander-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20.9963463406\n",
      "-27.6007577435\n",
      "134.102234544\n",
      "16.3842251285\n",
      "31.8511401825\n",
      "77.3356597707\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d3c387aa330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0menv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_polygon\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLunarLander\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mgeom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mgeom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mglBegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_LINE_LOOP\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mGL_LINE_STRIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mglVertex3f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# draw each vertex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mglEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_linewidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env2 = gym.make('LunarLander-v2')\n",
    "\n",
    "for i_episode in count(1):\n",
    "    state = env.reset()\n",
    "    env2.reset()\n",
    "    total_reward = 0\n",
    "    for t in range(10000):\n",
    "        action = select_action(state)\n",
    "        state, reward, done, _ = env.step(action[0,0])\n",
    "        env2.step(np.random.randint(4))\n",
    "        \n",
    "        env.render()\n",
    "        env2.render()\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(total_reward)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
