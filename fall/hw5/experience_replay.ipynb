{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple q-learning agent with experience replay\n",
    "\n",
    "We re-write q-learning algorithm using _agentnet_ - a helper for lasagne that implements some RL techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS='floatX=float32'\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "* Here we simply load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:32:56,748] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"LunarLander-v2\")\n",
    "\n",
    "env=make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import elu\n",
    "\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,)+state_shape)\n",
    "\n",
    "\n",
    "nn = DenseLayer(observation_layer, 200, nonlinearity=elu)\n",
    "nn = DenseLayer(nn, 200, nonlinearity=elu)\n",
    "\n",
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(nn,num_units=n_actions,\n",
    "                           nonlinearity=None,name=\"q-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking actions is done by yet another layer, that implements $ \\epsilon$ -greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "#set starting epsilon\n",
    "action_layer.epsilon.set_value(np.float32(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "We define an agent entirely composed of a lasagne network:\n",
    "* Observations as InputLayer(s)\n",
    "* Actions as intermediate Layer(s)\n",
    "* `policy_estimators` is \"whatever else you want to keep track of\"\n",
    "\n",
    "Each parameter can be either one layer or a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              action_layers=action_layer,\n",
    "              policy_estimators=qvalues_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, q-values.W, q-values.b]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:32:58,913] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "pool = EnvPool(agent,make_env,n_games=1,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [[3 3 3 3 3]]\n",
      "rewards: [[-1.11105027 -1.05721358 -1.73667379 -1.969974    0.        ]]\n",
      "CPU times: user 4.25 ms, sys: 2.7 ms, total: 6.96 ms\n",
      "Wall time: 5.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "obs_log,action_log,reward_log,_,_,_  = pool.interact(5)\n",
    "\n",
    "\n",
    "print('actions:',action_log)\n",
    "print('rewards:',reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we'll train on rollouts of 10 steps (required by n-step algorithms and rnns later)\n",
    "SEQ_LENGTH=10\n",
    "\n",
    "#load first sessions (this function calls interact and stores sessions in the pool)\n",
    "\n",
    "for _ in range(100):\n",
    "    pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-learning\n",
    "\n",
    "We shall now define a function that replays recent game sessions and updates network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100)\n",
    "qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2, like you implemented before in lasagne.\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,\n",
    "                                                      n_steps=1,)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get weight updates\n",
    "updates = lasagne.updates.adam(loss,weights,learning_rate=1e-4)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run\n",
    "\n",
    "Play full session with an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:33:05,235] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:05,248] Clearing 8 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:33:05,255] Starting new video recorder writing to /Users/AntonKarazeev/WD/mipt_hw/records/openaigym.video.5.59897.video000000.mp4\n",
      "[2017-11-05 01:33:07,614] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 58 timesteps with reward=-555.8726577113229\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.59897.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1 #starting epoch\n",
    "rewards = {} #full game rewards\n",
    "target_score = -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 99/1000 [00:05<00:45, 19.87it/s][2017-11-05 01:33:29,257] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:29,268] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:33:29,528] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 95 timesteps with reward=-159.82082361174167\n",
      "Episode finished after 115 timesteps with reward=-135.11981594927454\n",
      "Episode finished after 129 timesteps with reward=-246.05375694184414\n",
      "iter=100\tepsilon=0.910\n",
      "Current score(mean over 3) = -180.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 199/1000 [00:10<00:41, 19.12it/s][2017-11-05 01:33:34,986] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:34,994] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:33:35,188] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 20%|██        | 201/1000 [00:11<01:07, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 73 timesteps with reward=-120.44162507428929\n",
      "Episode finished after 126 timesteps with reward=-172.32343639317583\n",
      "Episode finished after 113 timesteps with reward=-630.2822908291743\n",
      "iter=200\tepsilon=0.828\n",
      "Current score(mean over 3) = -307.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 298/1000 [00:16<00:39, 17.62it/s][2017-11-05 01:33:40,798] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:40,807] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:33:41,108] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 30%|███       | 300/1000 [00:16<01:11,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 162 timesteps with reward=-348.0326640110933\n",
      "Episode finished after 189 timesteps with reward=-576.0171051623773\n",
      "Episode finished after 138 timesteps with reward=-242.0425588613409\n",
      "iter=300\tepsilon=0.754\n",
      "Current score(mean over 3) = -388.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 398/1000 [00:23<00:33, 17.80it/s][2017-11-05 01:33:47,616] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:47,624] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 73 timesteps with reward=-169.3562672570085\n",
      "Episode finished after 245 timesteps with reward=-250.89500582145067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:33:47,904] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 40%|████      | 402/1000 [00:23<00:54, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 83 timesteps with reward=-214.02276580233104\n",
      "iter=400\tepsilon=0.687\n",
      "Current score(mean over 3) = -211.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 498/1000 [00:29<00:28, 17.63it/s][2017-11-05 01:33:54,191] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:33:54,201] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 186 timesteps with reward=-226.47349365145485\n",
      "Episode finished after 113 timesteps with reward=-75.23985197717037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:33:54,619] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 50%|█████     | 502/1000 [00:30<00:53,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 220 timesteps with reward=-639.0739211760753\n",
      "iter=500\tepsilon=0.626\n",
      "Current score(mean over 3) = -313.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 598/1000 [00:38<00:33, 11.85it/s][2017-11-05 01:34:02,753] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:34:02,762] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:34:03,009] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 60%|██████    | 600/1000 [00:38<00:47,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 135 timesteps with reward=-319.2866226714124\n",
      "Episode finished after 90 timesteps with reward=-217.07755441998074\n",
      "Episode finished after 143 timesteps with reward=-86.32558865686943\n",
      "iter=600\tepsilon=0.571\n",
      "Current score(mean over 3) = -207.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 698/1000 [00:45<00:19, 15.81it/s][2017-11-05 01:34:09,654] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:34:09,664] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:34:09,914] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 70%|███████   | 700/1000 [00:45<00:30,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 140 timesteps with reward=-362.8532967799927\n",
      "Episode finished after 107 timesteps with reward=-535.471029392415\n",
      "Episode finished after 91 timesteps with reward=-278.6625033311692\n",
      "iter=700\tepsilon=0.522\n",
      "Current score(mean over 3) = -392.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 798/1000 [00:53<00:13, 14.87it/s][2017-11-05 01:34:18,157] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:34:18,166] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:34:18,471] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 80%|████████  | 800/1000 [00:54<00:22,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 181 timesteps with reward=-318.3122095449252\n",
      "Episode finished after 114 timesteps with reward=-392.7562891905704\n",
      "Episode finished after 188 timesteps with reward=-461.31541281408363\n",
      "iter=800\tepsilon=0.477\n",
      "Current score(mean over 3) = -390.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 898/1000 [01:01<00:07, 14.22it/s][2017-11-05 01:34:25,562] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:34:25,570] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 148 timesteps with reward=-654.4404645203474\n",
      "Episode finished after 218 timesteps with reward=-570.1305510938339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:34:25,972] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      " 90%|█████████ | 902/1000 [01:01<00:10,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 214 timesteps with reward=-786.6663217608186\n",
      "iter=900\tepsilon=0.436\n",
      "Current score(mean over 3) = -670.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 998/1000 [01:08<00:00, 15.50it/s][2017-11-05 01:34:32,522] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:34:32,531] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 138 timesteps with reward=-717.3487455395887\n",
      "Episode finished after 165 timesteps with reward=-464.9145792096632\n",
      "Episode finished after 149 timesteps with reward=-434.1266411733663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:34:32,817] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n",
      "100%|██████████| 1000/1000 [01:08<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.399\n",
      "Current score(mean over 3) = -538.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(1000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122aaa6a0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERQGIiIC/H/Wy3+e5fjRHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11826ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import ewma\n",
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda k:k[0]))\n",
    "plt.plot(iters,ewma(np.array(session_rewards),span=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:35:43,815] Making new env: LunarLander-v2\n",
      "[2017-11-05 01:35:43,827] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-05 01:35:43,833] Starting new video recorder writing to /Users/AntonKarazeev/WD/mipt_hw/records/openaigym.video.16.59897.video000000.mp4\n",
      "[2017-11-05 01:35:45,724] Starting new video recorder writing to /Users/AntonKarazeev/WD/mipt_hw/records/openaigym.video.16.59897.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 103 timesteps with reward=-234.36389963783375\n",
      "Episode finished after 191 timesteps with reward=-322.53746637275145\n",
      "Episode finished after 145 timesteps with reward=-532.5478237354165\n",
      "Episode finished after 164 timesteps with reward=-566.7982091312908\n",
      "Episode finished after 165 timesteps with reward=-283.1939207705934\n",
      "Episode finished after 102 timesteps with reward=-202.67568070597474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:35:49,199] Starting new video recorder writing to /Users/AntonKarazeev/WD/mipt_hw/records/openaigym.video.16.59897.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 170 timesteps with reward=-525.7999878323158\n",
      "Episode finished after 203 timesteps with reward=-803.2953567524714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:35:53,128] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/AntonKarazeev/WD/mipt_hw/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 265 timesteps with reward=-417.67917171791083\n",
      "Episode finished after 150 timesteps with reward=-261.28202686357804\n",
      "average reward: [-234.36389963783375, -322.53746637275145, -532.5478237354165, -566.79820913129083, -283.19392077059342, -202.67568070597474, -525.79998783231576, -803.29535675247143, -417.67917171791083, -261.28202686357804]\n"
     ]
    }
   ],
   "source": [
    "final_reward = pool.evaluate(n_games=10,save_path=\"./records\",record_video=True)\n",
    "\n",
    "print(\"average reward:\",final_reward)\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "for video_name in video_names:\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"{}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\".format(\"./records/\"+video_name)) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
